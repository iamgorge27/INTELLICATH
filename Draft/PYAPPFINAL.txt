import ssl
import math
import pickle
import pymysql  
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from apscheduler.schedulers.background import BackgroundScheduler

app = Flask(__name__)
CORS(app)

model = pickle.load(open('models/model_1.pkl', 'rb'))
poly = pickle.load(open('models/polynomial_features.pkl', 'rb'))
scaler = pickle.load(open('models/scaler.pkl', 'rb'))

DB_HOST = "localhost"
DB_USER = "root"
DB_PASSWORD = ""
DB_NAME = "intellicath"

def get_db_connection():
    return pymysql.connect(host=DB_HOST, user=DB_USER, password=DB_PASSWORD, database=DB_NAME, cursorclass=pymysql.cursors.DictCursor)

latest_data = {}

@app.route("/")
def index():
    return render_template("index.html")

@app.route("/predict-post", methods=["POST"])
def predict():
    global latest_data
    data = request.get_json()
    
    if not data:
        return jsonify({"error": "No data received"}), 400

    try:
        urine_output = data.get("urine_output")
        urine_flow_rate = data.get("urine_flow_rate")
        catheter_bag_volume = data.get("catheter_bag_volume")
        remaining_volume = data.get("remaining_volume")

        if None in [urine_output, urine_flow_rate, catheter_bag_volume, remaining_volume]:
            return jsonify({"error": "Incomplete data provided"}), 400

        features = [urine_output, urine_flow_rate, catheter_bag_volume, remaining_volume]
        features_scaled = scaler.transform(poly.transform([features]))
        predicted_time = model.predict(features_scaled)[0]

        hours = math.floor(predicted_time)
        minutes = round((predicted_time - hours) * 60)
        if hours >= 24:
            hours = 0
        predicted_time = f"{int(hours):02} hours and {int(minutes):02} minutes"

        latest_data = {
            "urine_output": urine_output,
            "urine_flow_rate": urine_flow_rate,
            "catheter_bag_volume": catheter_bag_volume,
            "remaining_volume": remaining_volume,
            "predicted_time": predicted_time
        }

        return jsonify(latest_data)

    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/predict-get", methods=["GET"])
def get_latest_data():
    global latest_data
    if not latest_data:
        return jsonify({"error": "No data available yet"}), 404
    return jsonify(latest_data)

def send_data_to_db():
    global latest_data
    if latest_data.get("urine_output") is not None: 
        try:
            connection = get_db_connection()
            with connection.cursor() as cursor:
                sql = """
                INSERT INTO intellicath_data (urine_output, urine_flow_rate, catheter_bag_volume, remaining_volume, predicted_time)
                VALUES (%s, %s, %s, %s, %s)
                """
                cursor.execute(sql, (
                    latest_data["urine_output"], 
                    latest_data["urine_flow_rate"], 
                    latest_data["catheter_bag_volume"], 
                    latest_data["remaining_volume"], 
                    latest_data["predicted_time"]
                ))
                connection.commit()

            connection.close()
            print("Data inserted into database")
        except Exception as e:
            print(f"Error in inserting data: {e}")
    else:
        print("No data available to send")

def start_scheduler():
    scheduler = BackgroundScheduler()
    scheduler.add_job(send_data_to_db, 'interval', hours=1) 
    scheduler.start()
    print("[Scheduler] started successfully")

if __name__ == "__main__":
    start_scheduler()
    context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)
    context.load_cert_chain(certfile="localhost.pem", keyfile="localhost-key.pem")
    app.run(debug=True, host="0.0.0.0", port=5001, ssl_context=context)
